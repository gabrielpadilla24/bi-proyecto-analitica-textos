# Etapa 1 - Proyecto Inteligencia de Negocios  
### Grupo 27  
**Autores:** Gabriel Padilla, Juan Pablo Rivera  

---

## Secci贸n 1. (20%) Documentaci贸n del proceso de aprendizaje autom谩tico  

Para esta secci贸n se complet贸 el **Canvas de Aprendizaje Autom谩tico** siguiendo la adaptaci贸n de *OWNML MACHINE LEARNING CANVAS* (CRISP-ML(Q): The ML Lifecycle Process).  

 **Canvas del proyecto (PDF):**  
[Descargar Canvas de Aprendizaje Autom谩tico](./canvas_model.pdf)

---


## Secci贸n 2. (20%) Entendimiento y preparaci贸n de los datos

En esta etapa se realiz贸 un **perfilamiento de los datos** con el fin de analizar su calidad, consistencia y completitud. El proceso incluy贸 las siguientes tareas:

1. **Exploraci贸n inicial de los datos**  
   - Identificaci贸n de columnas relevantes para el problema de clasificaci贸n de texto.  
   - Revisi贸n de valores nulos, duplicados y distribuci贸n de las variables.  
   - An谩lisis descriptivo para entender la representatividad de cada clase.

2. **Calidad de los datos**  
   - Se verific贸 la existencia de inconsistencias en los registros (ejemplo: textos vac铆os o mal codificados).  
   - Se eliminaron valores duplicados y se estandarizaron entradas inconsistentes.  
   - Se revis贸 la distribuci贸n de las clases para evaluar si exist铆a desbalance.

3. **Tratamiento de los datos**  
   - **Limpieza de texto:** conversi贸n a min煤sculas, eliminaci贸n de caracteres especiales y stopwords.  
   - **Tokenizaci贸n:** segmentaci贸n del texto en palabras para facilitar el an谩lisis.  
   - **Lematizaci贸n/Stemming:** reducci贸n de las palabras a su forma ra铆z para mejorar la representaci贸n.  
   - **Vectorizaci贸n:** uso de representaciones como *TF-IDF* para transformar el texto en vectores num茅ricos.  

4. **Transformaciones aplicadas seg煤n los algoritmos seleccionados**  
   - Para **Naive Bayes Multinomial**, se emple贸 TF-IDF como representaci贸n de texto, dado que este modelo se beneficia de frecuencias normalizadas.  
   - Para **Regresi贸n Log铆stica** y **SVM**, tambi茅n se utiliz贸 TF-IDF, asegurando que las variables tuvieran la misma escala para optimizar la convergencia y precisi贸n.  

5. **Preparaci贸n final de los datos**  
   - Divisi贸n del dataset en **conjunto de entrenamiento y prueba** con una proporci贸n de 80/20.  
   - Validaci贸n cruzada en la etapa de modelado para asegurar generalizaci贸n.  
   - Exportaci贸n de los datos procesados para su uso en los diferentes algoritmos.  

En conclusi贸n, el proceso de **entendimiento y preparaci贸n de los datos** permiti贸 garantizar que la informaci贸n utilizada en el modelado fuera **limpia, balanceada y transformada** adecuadamente, alineada con las t茅cnicas y algoritmos definidos para resolver el problema planteado.
