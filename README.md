# Etapa 1 - Proyecto Inteligencia de Negocios  
### Grupo 27  
**Autores:** Gabriel Padilla, Juan Pablo Rivera  

---

## Secci√≥n 1. (20%) Documentaci√≥n del proceso de aprendizaje autom√°tico  

Para esta secci√≥n se complet√≥ el **Canvas de Aprendizaje Autom√°tico** siguiendo la adaptaci√≥n de *OWNML MACHINE LEARNING CANVAS* (CRISP-ML(Q): The ML Lifecycle Process).  

üìé **Canvas del proyecto (PDF):**  
[Descargar Canvas de Aprendizaje Autom√°tico](./canvas_model.pdf)

---


## Secci√≥n 2. (20%) Entendimiento y preparaci√≥n de los datos

En esta etapa se realiz√≥ un **perfilamiento de los datos** con el fin de analizar su calidad, consistencia y completitud. El proceso incluy√≥ las siguientes tareas:

1. **Exploraci√≥n inicial de los datos**  
   - Identificaci√≥n de columnas relevantes para el problema de clasificaci√≥n de texto.  
   - Revisi√≥n de valores nulos, duplicados y distribuci√≥n de las variables.  
   - An√°lisis descriptivo para entender la representatividad de cada clase.

2. **Calidad de los datos**  
   - Se verific√≥ la existencia de inconsistencias en los registros (ejemplo: textos vac√≠os o mal codificados).  
   - Se eliminaron valores duplicados y se estandarizaron entradas inconsistentes.  
   - Se revis√≥ la distribuci√≥n de las clases para evaluar si exist√≠a desbalance.

3. **Tratamiento de los datos**  
   - **Limpieza de texto:** conversi√≥n a min√∫sculas, eliminaci√≥n de caracteres especiales y stopwords.  
   - **Tokenizaci√≥n:** segmentaci√≥n del texto en palabras para facilitar el an√°lisis.  
   - **Lematizaci√≥n/Stemming:** reducci√≥n de las palabras a su forma ra√≠z para mejorar la representaci√≥n.  
   - **Vectorizaci√≥n:** uso de representaciones como *TF-IDF* para transformar el texto en vectores num√©ricos.  

4. **Transformaciones aplicadas seg√∫n los algoritmos seleccionados**  
   - Para **Naive Bayes Multinomial**, se emple√≥ TF-IDF como representaci√≥n de texto, dado que este modelo se beneficia de frecuencias normalizadas.  
   - Para **Regresi√≥n Log√≠stica** y **SVM**, tambi√©n se utiliz√≥ TF-IDF, asegurando que las variables tuvieran la misma escala para optimizar la convergencia y precisi√≥n.  

5. **Preparaci√≥n final de los datos**  
   - Divisi√≥n del dataset en **conjunto de entrenamiento y prueba** con una proporci√≥n de 80/20.  
   - Validaci√≥n cruzada en la etapa de modelado para asegurar generalizaci√≥n.  
   - Exportaci√≥n de los datos procesados para su uso en los diferentes algoritmos.  

En conclusi√≥n, el proceso de **entendimiento y preparaci√≥n de los datos** permiti√≥ garantizar que la informaci√≥n utilizada en el modelado fuera **limpia, balanceada y transformada** adecuadamente, alineada con las t√©cnicas y algoritmos definidos para resolver el problema planteado.

---

## Secci√≥n 3. (20%) Modelado y selecci√≥n del modelo final

En esta etapa se entrenaron y evaluaron tres algoritmos de clasificaci√≥n de texto: **Naive Bayes Multinomial**, **Regresi√≥n Log√≠stica** y **SVM (Support Vector Machine)**. El proceso incluy√≥ los siguientes pasos:

1. **Definici√≥n de los modelos a entrenar**
   - **Naive Bayes Multinomial (NB):** Modelo probabil√≠stico simple basado en la independencia condicional de las palabras.  
   - **Regresi√≥n Log√≠stica (LR):** Modelo lineal discriminativo utilizado para clasificaci√≥n binaria y multiclase, optimizado mediante gradiente descendente.  
   - **SVM (Support Vector Machine):** Modelo que busca un hiperplano √≥ptimo para separar las clases maximizando el margen entre ellas.

2. **Pipeline de entrenamiento**
   - Transformaci√≥n de texto mediante **TF-IDF** para todos los modelos.  
   - Divisi√≥n del dataset en **conjunto de entrenamiento (80%) y prueba (20%)**.  
   - Validaci√≥n cruzada para evaluar estabilidad del rendimiento.  
   - Optimizaci√≥n de hiperpar√°metros en Regresi√≥n Log√≠stica y SVM.  

3. **Resultados obtenidos (m√©trica F1-macro)**

| Modelo               | F1-macro |
|-----------------------|----------|
| Naive Bayes          | 0.9353   |
| Regresi√≥n Log√≠stica  | 0.9577   |
| SVM                  | 0.9631   |

4. **Interpretaci√≥n de resultados**
   - **Naive Bayes:** Alcanz√≥ un rendimiento aceptable (F1 ‚âà 0.93), aunque con limitaciones en clases minoritarias.  
   - **Regresi√≥n Log√≠stica:** Mejor√≥ notablemente el rendimiento (F1 ‚âà 0.96), mostrando balance entre precisi√≥n y recall.  
   - **SVM:** Obtuvo el mejor desempe√±o (F1 ‚âà 0.963), con mayor capacidad para distinguir entre clases y reduciendo errores en la matriz de confusi√≥n.

5. **Selecci√≥n del modelo final**
   - Se seleccion√≥ **SVM (Support Vector Machine)** como el modelo final debido a:
     - Su mayor **F1-macro**.  
     - Balance √≥ptimo entre precisi√≥n y recall.  
     - Mejor generalizaci√≥n y robustez frente a casos ambiguos.  

Este modelo ser√° utilizado en las siguientes etapas del proyecto para la implementaci√≥n y validaci√≥n final.

### Contribuci√≥n de los integrantes
- **Naive Bayes Multinomial:** desarrollado por **Juan Pablo Rivera**.  
- **Regresi√≥n Log√≠stica:** desarrollada por **Gabriel Padilla**.  
- **SVM:** implementado y ajustado en conjunto por **Gabriel Padilla y Juan Pablo Rivera**.

---

---

## Secci√≥n 5. (8%) Trabajo en equipo

### Roles y responsabilidades
- **Gabriel Padilla**  
  - Rol: L√≠der de proyecto y L√≠der de negocio.  
  - Tareas realizadas: Implementaci√≥n del modelo de **Regresi√≥n Log√≠stica**, participaci√≥n conjunta en el modelo **SVM**, procesamiento de los datos, apoyo en la documentaci√≥n y estructuraci√≥n de la wiki.  
  - Tiempo dedicado: ~10 horas.  
  - Retos enfrentados: Coordinaci√≥n general del proyecto, reinstalaci√≥n del kernel de Jupyter y ajuste de dependencias.  
  - Uso de ChatGPT: Comprensi√≥n del problema, desglose de la metodolog√≠a, apoyo en la escritura en formato Markdown y estructuraci√≥n de la wiki. Uso de GitHub Copilot para apoyo en sintaxis de programaci√≥n.

- **Juan Pablo Rivera**  
  - Rol: L√≠der de datos y L√≠der de anal√≠tica.  
  - Tareas realizadas: Implementaci√≥n del modelo de **Naive Bayes**, participaci√≥n conjunta en el modelo **SVM**, limpieza de datos, apoyo en la documentaci√≥n y validaci√≥n de resultados.  
  - Tiempo dedicado: ~10 horas.  
  - Retos enfrentados: Problemas con librer√≠as en el entorno, reinstalaci√≥n del kernel de Jupyter y resoluci√≥n de inconsistencias de datos.  
  - Uso de ChatGPT: Consulta de algoritmos, gu√≠a del modelado, explicaci√≥n de m√©tricas y apoyo en la documentaci√≥n en Markdown. Uso de GitHub Copilot para asistencia en programaci√≥n.

### Distribuci√≥n de puntos
La distribuci√≥n de 100 puntos entre los integrantes se realiz√≥ de manera equitativa, dado que ambos contribuyeron en partes complementarias del proyecto:

- Gabriel Padilla: **50 puntos**  
- Juan Pablo Rivera: **50 puntos**

### Puntos a mejorar
- Optimizar el tiempo de reuniones y coordinaci√≥n.  
- Mejorar la organizaci√≥n del repositorio para separar claramente c√≥digo, datos y documentaci√≥n.  
- Ampliar el uso de m√©tricas adicionales para validar los modelos.  

